@article{kaul2020inference,
 abstract = {We study a plug in least squares estimator for the change point parameter where change is in the mean of a high dimensional random vector under subgaussian or subexponential distributions. We obtain sufficient conditions under which this estimator possesses sufficient adaptivity against plug in estimates of mean parameters in order to yield an optimal rate of convergence $O_p(ξ^-2)$ in the integer scale. This rate is preserved while allowing high dimensionality as well as a potentially diminishing jump size $ξ,$ provided $słog (pěe T)=o(√(Tl_T))$ or $słog^3/2(p\ě T)=o(√(Tl_T))$ in the subgaussian and subexponential cases, respectively. Here $s,p,T$ and $l_T$ represent a sparsity parameter, model dimension, sampling period and the separation of the change point from its parametric boundary, respectively. Moreover, since the rate of convergence is free of $s,p$ and logarithmic terms of $T,$ it allows the existence of limiting distributions under high dimensional asymptotics. These distributions are then derived as the ıt argmax of a two sided negative drift Brownian motion or a two sided negative drift random walk under vanishing and non-vanishing jump size regimes, respectively, thereby allowing inference on the change point parameter. Feasible algorithms for implementation of the proposed methodology are provided. Theoretical results are supported with monte-carlo simulations.},
 author = {Kaul, Abhishek and Fotopoulos, Stergios B and Jandhyala, Venkata K and Safikhani, Abolfazl},
 file = {:/Users/abhishekkaul/Documents/Publications bib/arxiv_ejs.pdf:PDF},
 journal = {arXiv preprint arXiv:2007.01888},
 keywords = {change point, inference, high dimensions, limiting distribution.},
 title = {Inference on the change point in high dimensional time series models via plug in least square},
 url = {media/arxiv_ejs.pdf},
 year = {2020}
}

